<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>philote_dev - Portfolio</title>
    <link rel="stylesheet" href="scripts/main.css">
</head>
<body>
    <nav>
        <a href="#home">Home</a>
        <a href="#home">About</a>
        <a href="#neural">Neural</a>
        <a href="#quantum">Quantum</a>
        <a href="#projects">Projects</a>
        <a href="#skills">Skills</a>
        <a href="#contact">Contact</a>
    </nav>

    <header id="home">
        <div class="header-content">
            <h1>Frank Gonzalez</h1>
            <p>Physics & CS @ MIT | AI/ML & Quantum Computing Researcher</p>
        </div>
        <div class="about-content" id="aboutContent">
            <h2>About Me</h2>
            <p>I'm a Physics and Computer Science student at MIT passionate about research in the intersection between quantum computing and artificial intelligence. My past work spans from quantum circuit optimization at CSAIL to neurosymbolic AI at MuLIP Labs. I have extensive robotics experience, competing at the World Championship level for numerous years, and I'm involved with AI safety organizations outside of school. Overall, I'm driven by creating tools/machines that bridge theoretical concepts with practical application.</p>
        </div>
    </header>

    <div class="fullscreen-viz" id="neural">
        <canvas id="neuralCanvas"></canvas>
        <div class="edu-card">
            <h3>Information Flow</h3>
            <p>Neurons activate based on proximity. Data propagates through layers via weighted connections.</p>
        </div>
        <div class="viz-content">
            <div class="viz-subtitle">Interactive Visualization</div>
            <h2 class="viz-title">Neural Network Dynamics</h2>
            <p class="viz-description">Vizualize how data flows through the connected layers by hovering over nodes to activate neurons.</p>
        </div>
    </div>

    <div class="fullscreen-viz" id="quantum">
        <canvas id="quantumCanvas"></canvas>
        <div class="edu-card">
            <h3>Quantum Superposition</h3>
            <p>States exist in superposition until measured. Apply unitary gates to rotate the state in Hilbert space.</p>
        </div>
        <div class="viz-content">
            <div class="viz-subtitle">Quantum Computing</div>
            <h2 class="viz-title">Bloch Sphere Simulator</h2>
            <p class="viz-description">Explore quantum state evolution. Apply gates to manipulate superposition and observe probability amplitudes transform (state listed on the top-right).</p>
        </div>
        <div class="quantum-info" id="quantumInfo">
            |ψ⟩ = 1.00|0⟩ + 0.00|1⟩
        </div>
        <div class="viz-controls">
            <button class="btn" onclick="applyHadamard()">Hadamard</button>
            <button class="btn" onclick="applyPauliX()">Pauli-X</button>
            <button class="btn" onclick="applyPhase()">Phase</button>
            <button class="btn" onclick="resetQuantum()">Reset</button>
        </div>
    </div>

    <div class="section-divider">
        <div class="divider-line"></div>
    </div>

    <section class="projects-section" id="projects">
        <h2>Featured Projects</h2>
            <div class="projects-grid">
                <div class="project-card" onclick="openModal('frcsim')">
                    <div class="project-image">
                        <img src="images/projects/frc vis sim.png" alt="FRC Simulations">
                    </div>
                    <div class="project-content">
                        <h3>FRC Simulations</h3>
                        <p>Comprehensive robotics system including physics-based simulation for driver practice, 
                            and robot state machine architecture.</p>
                        <div class="tech-stack">
                            <span class="tech-tag">Java</span>
                            <span class="tech-tag">Json</span>
                            <span class="tech-tag">AdvantageScope</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" onclick="openModal('frcai')">
                    <div class="project-image">
                        <img src="images/projects/frc btb.png" alt="FRC Vision AI">
                    </div>
                    <div class="project-content">
                        <h3>FRC Vision Recognition</h3>
                        <p>Boom Boom use vision to detect things , real-time autonomous object avoidance with camera-based 
                            path planning, AI object detection integration</p>
                        <div class="tech-stack">
                            <span class="tech-tag">Java</span>
                            <span class="tech-tag">Python</span>
                            <span class="tech-tag">OAK-D Pro</span>
                            <span class="tech-tag">PathPlanner</span>
                            <span class="tech-tag">CV</span>
                        </div>
                    </div>
                </div>
            
                <div class="project-card" onclick="openModal('novelgym')">
                    <div class="project-image">
                        <img src="images/projects/NovelGym Reg.png" alt="NovelGym Extension">
                    </div>
                    <div class="project-content">
                        <h3>NovelGym HITL Extension</h3>
                        <p>Extended NovelGym framework with Human-in-the-Loop feedback mechanisms for reinforcement learning agents. 
                            Research conducted at MuLIP Labs, Tufts University (RSI 2024).</p>
                        <div class="tech-stack">
                            <span class="tech-tag">Python</span>
                            <span class="tech-tag">RL</span>
                            <span class="tech-tag">PDDL</span>
                            <span class="tech-tag">GridWorld</span>
                        </div>
                    </div>
                </div>
            
                <div class="project-card" onclick="openModal('rubiks')">
                    <div class="project-image">
                        <img src="images/projects/Cube solver.png" alt="Rubik's Cube Solver">
                    </div>
                    <div class="project-content">
                        <h3>Rubik's Cube Solver</h3>
                        <p>Custom implementation of Kociemba's algorithm with optimized phase-state decomposition and pruning tables. 
                            Features 3D-printed hardware achieving 21-41 second solve times.</p>
                        <div class="tech-stack">
                            <span class="tech-tag">Python</span>
                            <span class="tech-tag">Arduino</span>
                            <span class="tech-tag">3D Printing</span>
                            <span class="tech-tag">Algorithms</span>
                        </div>
                    </div>
                </div>
            
                            
                <div class="project-card" onclick="openModal('sketch')">
                    <div class="project-image">
                        <img src="images/projects/Machining analyzer.png" alt="Sketch Visualizer">
                    </div>
                    <div class="project-content">
                        <h3>AI Sketch Visualizer <span style="color: #ebcb8b; font-size: 0.75em;">[Active Development]</span></h3>
                        <p>AI-driven engineering tool converting sketches to 3D models with manufacturability analysis. Uses CV for geometry 
                            extraction and AI for feasibility assessment.</p>
                        <div class="tech-stack">
                            <span class="tech-tag">Computer Vision</span>
                            <span class="tech-tag">LLMs</span>
                            <span class="tech-tag">Mesh Processing</span>
                            <span class="tech-tag">AI@MIT</span>
                        </div>
                    </div>
                </div>
            </div>
    </section>


    <!-- PROJECT MODALS -->
    <div id="modal-frc" class="modal" onclick="closeModal(event, 'frcsim')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="modal-close" onclick="closeModal(event, 'frcsim')">&times;</span>
            <div class="modal-header">
                <h2>FRC Simulations</h2>
                <p class="modal-subtitle">World Championship Competition System</p>
            </div>
            <div class="modal-body">
                <h3>Overview</h3>
                <p>Comprehensive robotics system developed for FIRST Robotics Competition, culminating in a semifinal appearance at the 2023 World Championship Galileo Division Finals. This suite represents a year of intensive development combining simulation, computer vision, and autonomous systems.</p>
                
                <h3>Key Components</h3>
                <ul>
                    <li><strong>Physics-Based Simulation:</strong> Custom simulator for driver practice and software testing without physical robot access, reducing development time and hardware wear</li>
                    <li><strong>Autonomous Object Avoidance:</strong> Real-time path planning system using OAK-D Pro camera with dynamic obstacle detection and path stitching</li>
                    <li><strong>AI Object Detection:</strong> Integrated computer vision pipeline for game piece recognition and field element tracking</li>
                    <li><strong>Robot State Machine:</strong> Robust state management architecture ensuring reliable autonomous and teleoperated modes</li>
                </ul>
                
                <h3>Technical Implementation</h3>
                <p>Built primarily in Java with Python integration for computer vision tasks. The object avoidance system uses PathPlanner paths with real-time nulled zones based on OAK-D Pro camera data, enabling dynamic replanning during autonomous periods.</p>
                
                <div class="modal-video">
                    <p style="text-align: center; padding: 2rem; color: #81a1c1;">Video demonstration coming soon - upload your FRC video to YouTube and add link here</p>
                </div>
                
                <h3>Impact</h3>
                <p>The autonomous system performed flawlessly during competition, allowing our robot to navigate complex field dynamics with unprecedented precision. This project taught me the importance of robust testing, modular architecture, and the practical challenges of deploying AI systems in high-stakes environments.</p>
                
                <div class="modal-links">
                    <a href="#contact" class="modal-btn">Request Demo Video</a>
                </div>
            </div>
        </div>
    </div>

    <div id="modal-frc" class="modal" onclick="closeModal(event, 'frcai')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="modal-close" onclick="closeModal(event, 'frcai')">&times;</span>
            <div class="modal-header">
                <h2>FRC Vision Recognition</h2>
                <p class="modal-subtitle">World Championship Competition System</p>
            </div>
            <div class="modal-body">
                <h3>Overview</h3>
                <p>Comprehensive robotics system developed for FIRST Robotics Competition, culminating in a semifinal appearance at the 2023 World Championship Galileo Division Finals. This suite represents a year of intensive development combining simulation, computer vision, and autonomous systems.</p>
                
                <h3>Key Components</h3>
                <ul>
                    <li><strong>Physics-Based Simulation:</strong> Custom simulator for driver practice and software testing without physical robot access, reducing development time and hardware wear</li>
                    <li><strong>Autonomous Object Avoidance:</strong> Real-time path planning system using OAK-D Pro camera with dynamic obstacle detection and path stitching</li>
                    <li><strong>AI Object Detection:</strong> Integrated computer vision pipeline for game piece recognition and field element tracking</li>
                    <li><strong>Robot State Machine:</strong> Robust state management architecture ensuring reliable autonomous and teleoperated modes</li>
                </ul>
                
                <h3>Technical Implementation</h3>
                <p>Built primarily in Java with Python integration for computer vision tasks. The object avoidance system uses PathPlanner paths with real-time nulled zones based on OAK-D Pro camera data, enabling dynamic replanning during autonomous periods.</p>
                
                <div class="modal-video">
                    <p style="text-align: center; padding: 2rem; color: #81a1c1;">Video demonstration coming soon - upload your FRC video to YouTube and add link here</p>
                </div>
                
                <h3>Impact</h3>
                <p>The autonomous system performed flawlessly during competition, allowing our robot to navigate complex field dynamics with unprecedented precision. This project taught me the importance of robust testing, modular architecture, and the practical challenges of deploying AI systems in high-stakes environments.</p>
                
                <div class="modal-links">
                    <a href="#contact" class="modal-btn">Request Demo Video</a>
                </div>
            </div>
        </div>
    </div>
    
    <div id="modal-novelgym" class="modal" onclick="closeModal(event, 'novelgym')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="modal-close" onclick="closeModal(event, 'novelgym')">&times;</span>
            <div class="modal-header">
                <h2>NovelGym HITL Extension</h2>
                <p class="modal-subtitle">RSI 2024 Research Project | MuLIP Labs, Tufts University</p>
            </div>
            <div class="modal-body">
                <h3>Research Overview</h3>
                <p>Extended the NovelGym framework to incorporate Human-in-the-Loop (HITL) feedback mechanisms for reinforcement learning agents operating in open-world scenarios with novelty. This research addresses a critical challenge in AI: how can agents adapt to unexpected situations by leveraging human expertise?</p>
                
                <h3>Key Contributions</h3>
                <ul>
                    <li><strong>HITL Framework:</strong> Developed interface for real-time human feedback integration during agent training and deployment</li>
                    <li><strong>Feedback Processing:</strong> Created mechanisms to translate natural language human guidance into actionable agent updates</li>
                    <li><strong>Adaptability Metrics:</strong> Established quantitative measures for agent improvement with human assistance</li>
                    <li><strong>GridWorld Implementation:</strong> Demonstrated system in controllable environment with diverse novelty types</li>
                </ul>
                
                <h3>Technical Approach</h3>
                <p>Built on Python-based NovelGym infrastructure using PDDL for domain specification and reinforcement learning algorithms for agent training. The HITL system accepts human feedback through multiple modalities and updates agent policies without full retraining.</p>
                
                <h3>Results & Impact</h3>
                <p>Demonstrated significant improvement in agent adaptability when human feedback was incorporated, particularly in scenarios with unexpected environmental changes. This work contributes to the broader goal of creating AI systems that can collaborate effectively with humans in uncertain environments.</p>
                
                <div class="modal-links">
                    <a href="https://github.com/tufts-ai-robotics-group/NovelGym" target="_blank" class="modal-btn">View on GitHub</a>
                    <a href="#contact" class="modal-btn">Request Research Paper</a>
                </div>
            </div>
        </div>
    </div>
    
    <div id="modal-rubiks" class="modal" onclick="closeModal(event, 'rubiks')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="modal-close" onclick="closeModal(event, 'rubiks')">&times;</span>
            <div class="modal-header">
                <h2>Rubik's Cube Solver</h2>
                <p class="modal-subtitle">Custom Kociemba Algorithm Implementation</p>
            </div>
            <div class="modal-body">
                <h3>Project Motivation</h3>
                <p>After years of speedcubing (averaging ~10 second solves), I wanted to understand the mathematics behind optimal solving algorithms rather than just memorizing patterns. This project became a deep dive into heuristic search, constraint satisfaction, and mechanical engineering.</p>
                
                <h3>Algorithm Development</h3>
                <ul>
                    <li><strong>Phase-State Decomposition:</strong> Implemented two-phase approach separating cube into subsets for efficient solving</li>
                    <li><strong>Pruning Tables:</strong> Generated comprehensive lookup tables to eliminate impossible move sequences</li>
                    <li><strong>Optimization:</strong> Custom heuristics reducing average move count and computation time</li>
                    <li><strong>Search Strategy:</strong> Iterative deepening A* with domain-specific pruning</li>
                </ul>
                
                <h3>Hardware Implementation</h3>
                <p>Designed and 3D-printed mechanical solver on Bambu Lab P1S. Six servo-controlled arms manipulate the cube with coordinated timing. Integration between software solver and hardware controller required careful calibration and error handling.</p>
                
                <h3>Performance</h3>
                <p>Achieves solve times of 21-41 seconds with move counts of 19-31, balancing optimality with computational efficiency. The project taught me invaluable lessons about the gap between theoretical algorithms and practical implementation.</p>
                
                <h3>Key Learnings</h3>
                <p>This project embodied patience and iteration—debugging mechanical timing issues, optimizing search algorithms, and calibrating servo movements required persistence. It reinforced my belief that the best learning comes from tackling problems just beyond your current skill set.</p>
                
                <div class="modal-links">
                    <a href="#contact" class="modal-btn">Request Technical Details</a>
                </div>
            </div>
        </div>
    </div>
    
        
    <div id="modal-sketch" class="modal" onclick="closeModal(event, 'sketch')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="modal-close" onclick="closeModal(event, 'sketch')">&times;</span>
            <div class="modal-header">
                <h2>AI Sketch Visualizer</h2>
                <p class="modal-subtitle">Active Development | AI@MIT</p>
            </div>
            <div class="modal-body">
                <h3>Project Vision</h3>
                <p>Creating an AI-powered engineering tool that democratizes design validation by converting hand-drawn sketches into 3D models with integrated manufacturability analysis. This addresses a critical barrier: students designing components for projects often lack the machining background to assess feasibility before investing in expensive CAD work.</p>
                
                <h3>Technical Approach</h3>
                <ul>
                    <li><strong>Computer Vision Pipeline:</strong> Processes isometric or multi-view orthographic sketches, cleaning and extracting geometric features</li>
                    <li><strong>3D Model Generation:</strong> Converts 2D sketches into 3D meshes using CV model trained on engineering drawings</li>
                    <li><strong>Manufacturability Analysis:</strong> Evaluates generated models for undercuts, overhangs, minimum feature sizes, and other machining constraints</li>
                    <li><strong>LLM Integration:</strong> Provides natural language feedback on design feasibility and suggested modifications</li>
                </ul>
                
                <h3>Current Status</h3>
                <p>In active development phase—prototyping CV model for sketch interpretation and establishing analysis framework. Key challenges include handling varied sketch quality, ambiguous geometric specifications, and balancing analysis depth with user accessibility.</p>
                
                <h3>Planned Features</h3>
                <ul>
                    <li>Interactive UI for sketch input and model visualization</li>
                    <li>Color-coded feasibility mapping (green/yellow/red highlighting)</li>
                    <li>Complexity scoring indicating required machining capabilities</li>
                    <li>Alternative design suggestions for problematic features</li>
                </ul>
                
                <h3>Future Impact</h3>
                <p>This tool aims to lower barriers to hardware prototyping, especially for students without access to premium CAD software or machining expertise. By providing rapid feedback on design feasibility, it enables faster iteration and more ambitious projects.</p>
                
                <div class="modal-links">
                    <a href="#contact" class="modal-btn">Follow Development</a>
                </div>
            </div>
        </div>
    </div>


    <div class="section-divider">
        <div class="divider-line"></div>
    </div>

    <section class="skills-section" id="skills">
        <h2>Technical Stack</h2>
        <div class="skills-grid">
            <div class="skill-box">
                <h3>Languages</h3>
                <ul>
                    <li>Python</li>
                    <li>JavaScript</li>
                    <li>C++</li>
                    <li>GLSL</li>
                </ul>
            </div>
            <div class="skill-box">
                <h3>Frameworks</h3>
                <ul>
                    <li>NumPy / Pandas</li>
                    <li>React</li>
                    <li>Three.js / WebGL</li>
                    <li>Canvas API</li>
                </ul>
            </div>
            <div class="skill-box">
                <h3>Specializations</h3>
                <ul>
                    <li>Quantum Computing</li>
                    <li>Data Visualization</li>
                    <li>Algorithm Design</li>
                    <li>Physics Simulation</li>
                </ul>
            </div>
            <div class="skill-box">
                <h3>Tools</h3>
                <ul>
                    <li>Git / GitHub</li>
                    <li>Performance Optimization</li>
                    <li>Real-time Rendering</li>
                    <li>API Design</li>
                </ul>
            </div>
        </div>
    </section>

    <div class="section-divider">
        <div class="divider-line"></div>
    </div>

    <section class="contact-section" id="contact">
        <h2>Contact </h2>
        <p>Interested in discussing projects or opportunities? Reach out—I'd love to talk.</p>
        <div class="contact-links">
            <a href="mailto:Frank_g@mit.edu">Email</a>
            <a href="https://github.com/philote-dev" target="_blank">GitHub</a>
            <a href="https://www.linkedin.com/in/frank-gonzalez-research" target="_blank">LinkedIn</a>
        </div>
    </section>

    <footer>
        <p>&copy; 2025 philote_dev. Built with passion for AI and quantum computing.</p>
    </footer>

    <!Script loading>
    <script src="scripts/main.js"></script>
    <script src="scripts/neural.js"></script>
    <script src="scripts/quantum.js"></script>


</body>
</html>
